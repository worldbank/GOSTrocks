{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import rasterio\n",
    "import pystac\n",
    "import pystac_client\n",
    "\n",
    "import GOSTrocks.rasterMisc as rMisc\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely.geometry import Polygon, Point, mapping, box\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "import GOSTrocks.dataMisc as dMisc\n",
    "import GOSTrocks.mapMisc as mapMisc\n",
    "\n",
    "\n",
    "import warnings\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "# Suppress only the InsecureRequestWarning from urllib3\n",
    "warnings.simplefilter('ignore', InsecureRequestWarning)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update to version 3.1\n",
    "In the summer of 2025, we received a complete update of the Fathom dataset labelled 3.1. This notebook will generate new VRTs for version 3.1 by manually editing the vrts from version 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FLOOD_MAP-1ARCSEC-NW_OFFSET-1in10-COASTAL-DEFENDED-DEPTH-2020-PERCENTILE50-v3.1',\n",
       " 'FLOOD_MAP-1ARCSEC-NW_OFFSET-1in10-COASTAL-DEFENDED-DEPTH-2030-SSP1_2.6-PERCENTILE50-v3.1',\n",
       " 'FLOOD_MAP-1ARCSEC-NW_OFFSET-1in10-COASTAL-DEFENDED-DEPTH-2030-SSP2_4.5-PERCENTILE50-v3.1',\n",
       " 'FLOOD_MAP-1ARCSEC-NW_OFFSET-1in10-COASTAL-DEFENDED-DEPTH-2030-SSP3_7.0-PERCENTILE50-v3.1',\n",
       " 'FLOOD_MAP-1ARCSEC-NW_OFFSET-1in10-COASTAL-DEFENDED-DEPTH-2030-SSP5_8.5-PERCENTILE50-v3.1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all folders in the new fathom 3.1 bucket\n",
    "s3_bucket = \"wbg-geography01\"\n",
    "s3_prefix = \"FATHOM/v31/\"\n",
    "s3 = boto3.client('s3', verify=False)\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=s3_bucket, Prefix=s3_prefix, Delimiter='/')\n",
    "new_fathom_models = []\n",
    "for page in pages:\n",
    "    for prefix in page.get('CommonPrefixes', []):\n",
    "        new_fathom_models.append(prefix.get('Prefix'))\n",
    "\n",
    "new_fathom_models = [f.split(\"/\")[-2] for f in new_fathom_models if f.endswith('v3.1/')]\n",
    "new_fathom_models[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate STAC catalog for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_list(model_path):\n",
    "    s3 = boto3.client('s3', verify=False)\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=s3_bucket, Prefix=model_path)\n",
    "\n",
    "    tile_list = []\n",
    "    for page in pages:\n",
    "        for obj in page.get('Contents', []):\n",
    "            if obj['Key'].endswith('.tif'):\n",
    "                tile_list.append(obj['Key'].split('/')[-1])\n",
    "    return tile_list\n",
    "\n",
    "def get_bbox_and_footprint(raster_uri):\n",
    "    with rasterio.Env(GDAL_HTTP_UNSAFESSL='YES'):\n",
    "        with rasterio.open(raster_uri) as ds:\n",
    "            bounds = ds.bounds\n",
    "            bbox = [bounds.left, bounds.bottom, bounds.right, bounds.top]\n",
    "            footprint = Polygon([\n",
    "                [bounds.left, bounds.bottom],\n",
    "                [bounds.left, bounds.top],\n",
    "                [bounds.right, bounds.top],\n",
    "                [bounds.right, bounds.bottom],\n",
    "                [bounds.left, bounds.bottom],\n",
    "            ])\n",
    "        return (bbox, mapping(footprint))\n",
    "    \n",
    "def get_bbox_and_footprint_dumb(file_name):\n",
    "    northing = file_name[:1]\n",
    "    long = int(file_name[1:3])\n",
    "    long2 = long + 1\n",
    "    if northing == 's':\n",
    "        long = long * -1\n",
    "        long2 = long2 * -1\n",
    "    easting = file_name[3:4]\n",
    "    lat = int(file_name[4:7])\n",
    "    lat2 = lat + 1\n",
    "    if easting == 'w':\n",
    "        lat = lat * -1\n",
    "        lat2 = lat2 * -1\n",
    "    \n",
    "    return ([long, lat, long2, lat2], mapping(box(long, lat, long2, lat2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31db1255f05f4190975c9049d7772c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tzinfo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m catalog\u001b[38;5;241m.\u001b[39mnormalize_hrefs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Temp/fathom_v31_stac_catalog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m catalog\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[1;32m---> 57\u001b[0m \u001b[43mcatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatalog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpystac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCatalogType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSELF_CONTAINED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\catalog.py:975\u001b[0m, in \u001b[0;36mCatalog.save\u001b[1;34m(self, catalog_type, dest_href, stac_io)\u001b[0m\n\u001b[0;32m    970\u001b[0m             child\u001b[38;5;241m.\u001b[39msave(\n\u001b[0;32m    971\u001b[0m                 dest_href\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(child_dest_href),\n\u001b[0;32m    972\u001b[0m                 stac_io\u001b[38;5;241m=\u001b[39mstac_io,\n\u001b[0;32m    973\u001b[0m             )\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 975\u001b[0m             \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstac_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstac_io\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item_link \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_item_links():\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item_link\u001b[38;5;241m.\u001b[39mis_resolved():\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\catalog.py:1011\u001b[0m, in \u001b[0;36mCatalog.save\u001b[1;34m(self, catalog_type, dest_href, stac_io)\u001b[0m\n\u001b[0;32m   1007\u001b[0m     rel_href \u001b[38;5;241m=\u001b[39m make_relative_href(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_href, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_href)\n\u001b[0;32m   1008\u001b[0m     catalog_dest_href \u001b[38;5;241m=\u001b[39m make_absolute_href(\n\u001b[0;32m   1009\u001b[0m         rel_href, dest_href, start_is_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     )\n\u001b[1;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_self_link\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_self_link\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdest_href\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatalog_dest_href\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstac_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstac_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m catalog_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcatalog_type \u001b[38;5;241m=\u001b[39m catalog_type\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\stac_object.py:476\u001b[0m, in \u001b[0;36mSTACObject.save_object\u001b[1;34m(self, include_self_link, dest_href, stac_io)\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m STACError(\n\u001b[0;32m    472\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelf HREF must be set before saving without an explicit dest_href.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    473\u001b[0m         )\n\u001b[0;32m    474\u001b[0m     dest_href \u001b[38;5;241m=\u001b[39m self_href\n\u001b[1;32m--> 476\u001b[0m stac_io\u001b[38;5;241m.\u001b[39msave_json(dest_href, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_self_link\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_self_link\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\collection.py:581\u001b[0m, in \u001b[0;36mCollection.to_dict\u001b[1;34m(self, include_self_link, transform_hrefs)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dict\u001b[39m(\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m, include_self_link: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, transform_hrefs: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    578\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto_dict(\n\u001b[0;32m    579\u001b[0m         include_self_link\u001b[38;5;241m=\u001b[39minclude_self_link, transform_hrefs\u001b[38;5;241m=\u001b[39mtransform_hrefs\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m     d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m     d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlicense\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlicense\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstac_extensions:\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\collection.py:339\u001b[0m, in \u001b[0;36mExtent.to_dict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns this extent as a dictionary.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m        dict: A serialization of the Extent.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     d \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial\u001b[38;5;241m.\u001b[39mto_dict(),\n\u001b[1;32m--> 339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporal\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemporal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_fields,\n\u001b[0;32m    341\u001b[0m     }\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\collection.py:230\u001b[0m, in \u001b[0;36mTemporalExtent.to_dict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     end \u001b[38;5;241m=\u001b[39m datetime_to_str(i[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\utils.py:386\u001b[0m, in \u001b[0;36mdatetime_to_str\u001b[1;34m(dt, timespec)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdatetime_to_str\u001b[39m(dt: datetime, timespec: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a :class:`datetime.datetime` instance to an ISO8601 string in the\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    `RFC 3339, section 5.6\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    <https://datatracker.ietf.org/doc/html/rfc3339#section-5.6>`__ format required by\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m        str: The ISO8601 (RFC 3339) formatted string representing the datetime.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtzinfo\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m         dt \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mreplace(tzinfo\u001b[38;5;241m=\u001b[39mtimezone\u001b[38;5;241m.\u001b[39mutc)\n\u001b[0;32m    389\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39misoformat(timespec\u001b[38;5;241m=\u001b[39mtimespec)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'tzinfo'"
     ]
    }
   ],
   "source": [
    "catalog = pystac.Catalog(\n",
    "    id=\"fathom-v31-catalog\",\n",
    "    description=\"STAC Catalog for FATHOM 3.1 global flood hazard data\",    \n",
    ")\n",
    "\n",
    "cur_model = 'FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1' #new_fathom_models[0]\n",
    "model_path = f\"FATHOM/v31/{cur_model}/\"\n",
    "all_tiles = get_tile_list(model_path)\n",
    "\n",
    "deets = cur_model.split(\"-\")\n",
    "return_period = deets[3]\n",
    "type = deets[4]\n",
    "defended = deets[5]\n",
    "date = deets[7]\n",
    "scenario = deets[8] if deets[8] != \"PERCENTILE50\" else \"Baseline\"\n",
    "\n",
    "spatial_extent = pystac.SpatialExtent(bboxes=[[-180.0, -90.0, 180.0, 90.0]])\n",
    "temporal_extent = pystac.TemporalExtent(intervals=[[f\"{date}-01-01T00:00:00Z\", f\"{date}-12-31T00:00:00Z\"]])\n",
    "\n",
    "c_collection = pystac.Collection(\n",
    "    id=cur_model,\n",
    "    description=f\"FATHOM 3.1 Flood Hazard Model: {type} flood, {defended}, {return_period} return period, {scenario} scenario, {date} data\",\n",
    "    title=f\"FATHOM 3.1 - {cur_model}\",\n",
    "    extent=pystac.Extent(spatial=spatial_extent, temporal=temporal_extent),\n",
    "    extra_fields={\n",
    "        \"model_type\": type,\n",
    "        \"defended_status\": defended,\n",
    "        \"return_period\": return_period,\n",
    "        \"scenario\": scenario,\n",
    "        \"data_year\": date,\n",
    "    }\n",
    ")\n",
    "\n",
    "for c_tile in tqdm(all_tiles[:10]):\n",
    "    raster_s3_uri = f\"s3://{s3_bucket}/{model_path}{c_tile}\"\n",
    "    bbox, footprint = get_bbox_and_footprint_dumb(c_tile)\n",
    "    item = pystac.Item(\n",
    "        id=c_tile.replace('.tif', ''),\n",
    "        geometry=footprint,\n",
    "        bbox=bbox,\n",
    "        datetime=pystac.utils.str_to_datetime(f\"{date}-01-01T00:00:00Z\"),\n",
    "        properties={},\n",
    "    )\n",
    "\n",
    "    asset = pystac.Asset(\n",
    "        href=raster_s3_uri,\n",
    "        media_type=pystac.MediaType.COG,\n",
    "        roles=[\"data\"],\n",
    "        title=c_tile,\n",
    "    )\n",
    "    item.add_asset(\"raster\", asset)\n",
    "\n",
    "    c_collection.add_item(item)\n",
    "\n",
    "catalog.add_child(c_collection)\n",
    "catalog.normalize_hrefs(\"C:/Temp/fathom_v31_stac_catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found item: n00e006 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n",
      "Found item: n00e009 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n",
      "Found item: n00e010 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n",
      "Found item: n00e011 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n",
      "Found item: n00e012 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n",
      "Found item: n00e013 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n",
      "Found item: n00e014 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n",
      "Found item: n00e015 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n",
      "Found item: n00e016 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n",
      "Found item: n00e017 in catalog FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1: 2020-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tzinfo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound item: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in catalog \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m catalog\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mcatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatalog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpystac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCatalogType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSELF_CONTAINED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\catalog.py:975\u001b[0m, in \u001b[0;36mCatalog.save\u001b[1;34m(self, catalog_type, dest_href, stac_io)\u001b[0m\n\u001b[0;32m    970\u001b[0m             child\u001b[38;5;241m.\u001b[39msave(\n\u001b[0;32m    971\u001b[0m                 dest_href\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(child_dest_href),\n\u001b[0;32m    972\u001b[0m                 stac_io\u001b[38;5;241m=\u001b[39mstac_io,\n\u001b[0;32m    973\u001b[0m             )\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 975\u001b[0m             \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstac_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstac_io\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item_link \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_item_links():\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item_link\u001b[38;5;241m.\u001b[39mis_resolved():\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\catalog.py:1011\u001b[0m, in \u001b[0;36mCatalog.save\u001b[1;34m(self, catalog_type, dest_href, stac_io)\u001b[0m\n\u001b[0;32m   1007\u001b[0m     rel_href \u001b[38;5;241m=\u001b[39m make_relative_href(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_href, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_href)\n\u001b[0;32m   1008\u001b[0m     catalog_dest_href \u001b[38;5;241m=\u001b[39m make_absolute_href(\n\u001b[0;32m   1009\u001b[0m         rel_href, dest_href, start_is_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     )\n\u001b[1;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_self_link\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_self_link\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdest_href\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatalog_dest_href\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstac_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstac_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m catalog_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcatalog_type \u001b[38;5;241m=\u001b[39m catalog_type\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\stac_object.py:476\u001b[0m, in \u001b[0;36mSTACObject.save_object\u001b[1;34m(self, include_self_link, dest_href, stac_io)\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m STACError(\n\u001b[0;32m    472\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelf HREF must be set before saving without an explicit dest_href.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    473\u001b[0m         )\n\u001b[0;32m    474\u001b[0m     dest_href \u001b[38;5;241m=\u001b[39m self_href\n\u001b[1;32m--> 476\u001b[0m stac_io\u001b[38;5;241m.\u001b[39msave_json(dest_href, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_self_link\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_self_link\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\collection.py:581\u001b[0m, in \u001b[0;36mCollection.to_dict\u001b[1;34m(self, include_self_link, transform_hrefs)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dict\u001b[39m(\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m, include_self_link: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, transform_hrefs: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    578\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto_dict(\n\u001b[0;32m    579\u001b[0m         include_self_link\u001b[38;5;241m=\u001b[39minclude_self_link, transform_hrefs\u001b[38;5;241m=\u001b[39mtransform_hrefs\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m     d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m     d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlicense\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlicense\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstac_extensions:\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\collection.py:339\u001b[0m, in \u001b[0;36mExtent.to_dict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns this extent as a dictionary.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m        dict: A serialization of the Extent.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     d \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial\u001b[38;5;241m.\u001b[39mto_dict(),\n\u001b[1;32m--> 339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporal\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemporal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_fields,\n\u001b[0;32m    341\u001b[0m     }\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\collection.py:230\u001b[0m, in \u001b[0;36mTemporalExtent.to_dict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     end \u001b[38;5;241m=\u001b[39m datetime_to_str(i[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\WBG\\Anaconda3\\envs\\s2s_ingest\\lib\\site-packages\\pystac\\utils.py:386\u001b[0m, in \u001b[0;36mdatetime_to_str\u001b[1;34m(dt, timespec)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdatetime_to_str\u001b[39m(dt: datetime, timespec: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a :class:`datetime.datetime` instance to an ISO8601 string in the\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    `RFC 3339, section 5.6\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    <https://datatracker.ietf.org/doc/html/rfc3339#section-5.6>`__ format required by\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m        str: The ISO8601 (RFC 3339) formatted string representing the datetime.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtzinfo\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m         dt \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mreplace(tzinfo\u001b[38;5;241m=\u001b[39mtimezone\u001b[38;5;241m.\u001b[39mutc)\n\u001b[0;32m    389\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39misoformat(timespec\u001b[38;5;241m=\u001b[39mtimespec)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'tzinfo'"
     ]
    }
   ],
   "source": [
    "for root, catalogs, items in catalog.walk():\n",
    "    for item in items:\n",
    "        print(f\"Found item: {item.id} in catalog {root.id}: {item.datetime}\")\n",
    "\n",
    "catalog.validate()\n",
    "catalog.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-create VRTs using existing templates\n",
    "\n",
    "THIS ISN'T WORKING !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class generate_vrt_from_template:\n",
    "    def __init__(self, template_vrt, new_dataset, old_dataset=None, new_vrt=None, good_tiles=None):\n",
    "        self.template_vrt = template_vrt\n",
    "        self.new_dataset = new_dataset\n",
    "        self.old_dataset = os.path.basename(template_vrt)[:-4] if old_dataset is None else old_dataset\n",
    "        self.new_vrt = self.template_vrt.replace(self.old_dataset, self.new_dataset) if new_vrt is None else new_vrt\n",
    "        self.good_tiles = good_tiles\n",
    "\n",
    "    def update_vrt(self):\n",
    "        tree = ET.parse(self.template_vrt)\n",
    "        root = tree.getroot()\n",
    "        parent = root.find(\"VRTRasterBand\")\n",
    "\n",
    "        for mega_parent in root.iter():\n",
    "            if mega_parent.tag == 'VRTRasterBand':\n",
    "                for parent in mega_parent.findall(\"SimpleSource\"):\n",
    "                    child = parent.find(\"SourceFilename\")\n",
    "                    cur_tif = child.text.split(\"/\")[-1]\n",
    "                    if cur_tif in self.good_tiles:\n",
    "                        child.text = self.new_dataset + \"/\" + cur_tif\n",
    "                    else:                        \n",
    "                        mega_parent.remove(parent)\n",
    "\n",
    "        tree.write(self.new_vrt, xml_declaration=False)\n",
    "\n",
    "# For each of the new Fathom models, create a new VRT file, based on existing templates\n",
    "out_folder = \"C:/Temp/fathom_vrts_v31/\"\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "standard_template_vrt = os.path.abspath(\"../sample_data/GLOBAL-1ARCSEC-NW_OFFSET-1in500-PLUVIAL-DEFENDED-DEPTH-2080-SSP5_8.5-PERCENTILE50-v3.0.vrt\")\n",
    "coastal_template_vrt = os.path.abspath(\"../sample_data/GLOBAL-1ARCSEC-NW_OFFSET-1in500-COASTAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.0.vrt\")\n",
    "\n",
    "for c_model in ['FLOOD_MAP-1ARCSEC-NW_OFFSET-1in100-FLUVIAL-UNDEFENDED-DEPTH-2020-PERCENTILE50-v3.1']: #tqdm(new_fathom_models):\n",
    "    cur_template = standard_template_vrt\n",
    "    if \"COASTAL\" in c_model:\n",
    "        cur_template = coastal_template_vrt \n",
    "    out_vrt = os.path.join(out_folder, f\"{c_model}.vrt\")\n",
    "    old_dataset = 'v2023/' + c_model.replace(\"v3.1\", \"v3.0\").replace(\"FLOOD_MAP\", \"GLOBAL\")\n",
    "    new_dataset = 'v31/' + c_model\n",
    "    existing_tiles = get_tile_list(f'FATHOM/{new_dataset}')\n",
    "    generate_vrt_from_template(cur_template, new_dataset, old_dataset=old_dataset, new_vrt=out_vrt, good_tiles=existing_tiles).update_vrt()\n",
    "    s3.upload_file(out_vrt, s3_bucket, f\"FATHOM/{c_model}.vrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a table of all new VRT files\n",
    "vrt_table = []\n",
    "for c_model in new_fathom_models:\n",
    "    vrt_path = f\"s3://{s3_bucket}/FATHOM/{c_model}.vrt\"\n",
    "    c = c_model.split(\"-\")\n",
    "    cur_vals = [c_model, c[3], c[4], c[5], c[7], c[8], vrt_path]\n",
    "    vrt_table.append(cur_vals)\n",
    "    \n",
    "# Write out the table to S3\n",
    "storage_options = {\n",
    "    'client_kwargs': {\n",
    "        'verify': False # Disable SSL verification\n",
    "    }\n",
    "}\n",
    "out_s3_dataframe = f's3://{s3_bucket}/FATHOM/fathom_v31_vrt_table.csv'\n",
    "pd.DataFrame(vrt_table, \n",
    "             columns=[\"model_name\", \"return\", \"type\", \"defended\", \"year\", \"scenario\", \"vrt_path\"]).to_csv(\n",
    "                out_s3_dataframe, \n",
    "                storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results\n",
    "iso3 = 'KEN'\n",
    "world_filepath = r'C:\\WBG\\Work\\data\\ADMIN\\NEW_WB_BOUNDS\\FOR_PUBLICATION\\gpkg\\WB_GAD_ADM0_complete.gpkg'\n",
    "world = gpd.read_file(world_filepath)\n",
    "inB = world.loc[world[\"ISO_A3\"] == iso3].copy()\n",
    "\n",
    "temp_s3_path = f\"s3://{s3_bucket}/FATHOM/{c_model}.vrt\"\n",
    "\n",
    "# open the VRT with rasterio and clip to the country boundary\n",
    "with rasterio.Env(GDAL_HTTP_UNSAFESSL=\"YES\"):\n",
    "    with rasterio.open(temp_s3_path) as src:\n",
    "        out_image, out_transform = rMisc.clipRaster(src, inB, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rMisc.create_rasterio_inmemory(out_transform, out_image) as clipped_raster:\n",
    "    mapMisc.static_map_raster(clipped_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rMisc.clipRaster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"wbg-geography01\"\n",
    "s3_prefix = \"FATHOM/v2023/\"\n",
    "s3_out = os.path.join(\"s3://\", s3_bucket, s3_prefix)\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "my_bucket = s3.Bucket(s3_bucket)\n",
    "\n",
    "# Find all files already copied\n",
    "all_folders = []\n",
    "for obj in my_bucket.objects.filter(Prefix=s3_prefix):\n",
    "    all_folders.append(obj.key.split(\"/\")[-2])\n",
    "all_folders\n",
    "all_folders = list(set(all_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build list of rasters for generating VRT\n",
    "local_path = os.path.join(\n",
    "    \"v2023\",\n",
    "    \"GLOBAL-1ARCSEC-NW_OFFSET-1in500-PLUVIAL-DEFENDED-DEPTH-2020-PERCENTILE50-v3.0\",\n",
    ")\n",
    "in_folder = os.path.join(template_folder, local_path)  # noqa\n",
    "all_tiffs = [f\"{local_path}/{x}\" for x in os.listdir(in_folder)]\n",
    "\n",
    "with open(os.path.join(template_folder, \"s3_tiffs.txt\"), \"w\") as out:  # noqa\n",
    "    for p in all_tiffs:\n",
    "        out.write(f\"{p}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_folder = \"/home/wb411133/temp\"\n",
    "coastal_template = os.path.join(\n",
    "    template_folder,\n",
    "    \"GLOBAL-1ARCSEC-NW_OFFSET-1in10-COASTAL-DEFENDED-DEPTH-2030-SSP3_7.0-PERCENTILE50-v3.0.0.vrt\",\n",
    ")\n",
    "other_template = os.path.join(\n",
    "    template_folder,\n",
    "    \"GLOBAL-1ARCSEC-NW_OFFSET-1in500-PLUVIAL-DEFENDED-DEPTH-2020-PERCENTILE50-v3.0.vrt\",\n",
    ")\n",
    "\n",
    "\n",
    "class generate_vrt_from_template:\n",
    "    def __init__(self, template_vrt, new_dataset):\n",
    "        self.template_vrt = template_vrt\n",
    "        self.new_dataset = new_dataset\n",
    "        self.old_dataset = os.path.basename(template_vrt)[:-4]\n",
    "        self.new_vrt = self.template_vrt.replace(self.old_dataset, self.new_dataset)\n",
    "\n",
    "    def update_vrt(self):\n",
    "        tree = ET.parse(self.template_vrt)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for child in root.iter(\"SourceFilename\"):\n",
    "            child.text = child.text.replace(self.old_dataset, self.new_dataset)\n",
    "\n",
    "        tree.write(self.new_vrt, xml_declaration=False)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "new_ds = \"GLOBAL-1ARCSEC-NW_OFFSET-1in10-COASTAL-DEFENDED-DEPTH-2030-SSP3_7.0-PERCENTILE50-v3.0\"\n",
    "xx = generate_vrt_from_template(template_vrt, new_ds)\n",
    "xx.update_vrt()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create template vrts\n",
    "for new_ds in all_folders:\n",
    "    flood_type = new_ds.split(\"-\")[4]\n",
    "    vrt_template = other_template\n",
    "    if flood_type == \"COASTAL\":\n",
    "        vrt_template = coastal_template\n",
    "    xx = generate_vrt_from_template(vrt_template, new_ds)\n",
    "    xx.update_vrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws s3 cp . s3://wbg-geography01/FATHOM/ --exclude \"*\" --include \"*.vrt\"  --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect copied VRTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dMisc.get_fathom_vrts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"wbg-geography01\"\n",
    "s3_prefix = \"FATHOM/\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "my_bucket = s3.Bucket(s3_bucket)\n",
    "\n",
    "all_vrts = []\n",
    "for o in my_bucket.objects.filter(Prefix=s3_prefix):\n",
    "    if o.key.endswith(\".vrt\"):\n",
    "        print(o.key)\n",
    "        full_vrt_path = f\"s3://{s3_bucket}/{o.key}\"\n",
    "        all_vrts.append(full_vrt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vrts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vrts[\"FLOOD_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vrts = dMisc.get_fathom_vrts(True)\n",
    "all_res = {}\n",
    "for idx, row in all_vrts.iterrows():\n",
    "    # vrt_path = row['PATH']\n",
    "    # xx = rasterio.open(vrt_path)\n",
    "    filename = os.path.basename(row[\"PATH\"])\n",
    "    year = row[\"YEAR\"]\n",
    "    climate_model = row[\"CLIMATE_MODEL\"]\n",
    "    if climate_model == \"PERCENTILE50\":\n",
    "        climate_model = \"CURRENT\"\n",
    "    flood_type = row[\"FLOOD_TYPE\"].lower()\n",
    "    defence = row[\"DEFENCE\"].lower()\n",
    "    ret = row[\"RETURN\"]\n",
    "    label = \"_\".join([flood_type, defence, ret, climate_model, year])\n",
    "    ret = ret.replace(\"in\", \" in \")\n",
    "    if year == \"2020\":\n",
    "        description = f\"Global {defence} {flood_type} flood model based on current climate. Flood depth is measured in cm expected flood depth, based on a {ret} year return period.\"\n",
    "    else:\n",
    "        description = f\"Global {defence} {flood_type} flood model based on {climate_model} climate model for year {year}. Flood depth is measured in cm expected flood depth, based on a {ret} year return period.\"\n",
    "    all_res[label] = {\"description\": description, \"filename\": row[\"PATH\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fathom_file_descriptions.json\", \"w\") as out_f:\n",
    "    json.dump(all_res, out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBURGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of files for gdalbuildvrt\n",
    "folder = \"/home/wb411133/temp/v2023/GLOBAL-1ARCSEC-NW_OFFSET-1in500-PLUVIAL-DEFENDED-DEPTH-2020-PERCENTILE50-v3.0\"\n",
    "all_files = [\n",
    "    f\"v2023/GLOBAL-1ARCSEC-NW_OFFSET-1in500-PLUVIAL-DEFENDED-DEPTH-2020-PERCENTILE50-v3.0/{x}\"\n",
    "    for x in os.listdir(folder)\n",
    "]\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2s_ingest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
